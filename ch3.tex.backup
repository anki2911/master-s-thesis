\chapter{Related research works}\label{ch3}
\noindent
Several techniques have been developed and adopted in real time predictable DRAM controllers. In normal systems, multiple 
requesters generate memory requests to the DRAM controller, which finally schedules the requests to the DRAM for processing 
the requests. In real time systems, each task is associated with a deadline which is expressed in terms of real time. Shared
resource access interference, such as memory and system bus, is very challenging for designing predictable real time system 
as WCET of a real time task significantly differ. In commercial off-the-shelf (COTS) DRAM controllers, scheduling techniques 
are generally applied at the software level. In custom memory controller, either techniques focus mainly on scheduling the 
memory requests or controlling the commands. So based on our requirements, we need to decide on the suitable address mapping 
scheme and page policy to be used.

\noindent
In COTS multicore systems, DRAM banks can be accessed independently. In~\cite{yun2014palloc}, PALLOC, a DRAM bank aware 
memory controller has been proposed. These memory controllers exploit the page-based virtual memory system to avoid bank 
sharing among cores, thereby improving isolation on COTS multicore platforms without requiring any special hardware support. 
In~\cite{kim2014bounding}, techniques have been proposed to provide a tight upper bound on the worst-case memory interference in COTS 
multi-core systems, where a task running on one core may get delayed by other task running on the other core due to shared 
resources. They have explicitly modeled the major resources in the DRAM system and considered timing characteristics by 
analyzing worst-case interference delay imposed by a parallelly running task on the other.

\noindent
A predictable DRAM controller design has been proposed in PRET~\cite{reineke2011pret}, where DRAM is considered as multiple 
resources that can be shared between one or more requests individually by interleaving accesses to blocks of DRAM. Thus 
contention for shared resources is eliminated within the device, making accesses temporally predictable and temporally 
isolated. Each memory request is scheduled by TDM and each DRAM command's latency is predefined, so each request is isolated 
and tightly bounded. Though this scheme is very useful for critical tasks, unused memory slots cannot be used for non critical
tasks and hence is very inefficient for those systems with large number of non critical tasks.

\noindent
Another approach has been mentioned in~\cite{akesson2011architectures} where bank interleaving and a close page policy are used with a per-defined 
command sequence. Different scheduling approaches such as dynamic scheduling can be used for systems where we have varying 
memory request patterns. But request isolation is not gauranted. Again in~\cite{akesson2008real}, a Credit-Controlled Static-Priority
(CCSP) has been suggested to provide minimum bandwidth for each request with bounded latencies. 

\noindent
Multicore processors handle hard real time systems for their good performance-watt-ratio and high performance capabilities.
Unfortunately, multicores are limited by the gaurantee of time composability for mixed critical applications as WCET of a task 
depends on inter-task interferences with other tasks executing simultaneously on the same platform. 
In~\cite{paolieri2013timing}, an analytical model that computes worst case delay, more specifically known as Upper Bound 
Delay (UBD) has been computed considering all memory interferences generated by co-running tasks. Another approach has been 
proposed in~\cite{goossens2013reconfigurable} where a method for composable service to memory clients by composable memory 
patterns has been designed. A reconfigurable TDM, which can be changed at run time along with a reconfigurable protocol has 
been developed, whereas, predictable and composable performance are also offered to active memory clients which remains 
unaffected irrespective of configuration. Each request is isolated from memory interference if each task is allocated 
a slot in the TDM. But, a lot of slots are wasted if no memory request occurs resulting in decrease in throughput. Also, in 
absence of critical tasks, no non critical tasks are allowed to execute in the slot assigned for critical task.

\noindent
Another approach has been developed in~\cite{kim2015predictable} where memory access groups (MAGs) are generated per bank 
and the tasks are combined to form these MAGs. Both critical and non critical MAGs are generated and each bank has certain 
critical space for execution of critical tasks. In absence of critical tasks, non critical tasks can execute in their place 
and they are pre-empted by critical tasks as soon as they arrive. The main disadvantage of this method is that each 
of critical MAG consists of one safety critical and two or more mission critical tasks. Therefore, some mission critical 
tasks may miss their deadlines while awaiting in the MAG for memory access. For systems, where the ratio of safety 
critical and mission critical tasks are same, a lot of safety critical tasks miss their deadline. An extension of this work 
has been discussed in this paper with some modifications to increase the number of hits of critical tasks.

\noindent
In 